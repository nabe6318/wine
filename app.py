import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from mlxtend.plotting import plot_decision_regions

st.set_page_config(page_title="Wine Logistic Regression Demo", layout="centered")

st.title("ğŸ· ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼ˆ2ç‰¹å¾´ Ã— å¤šã‚¯ãƒ©ã‚¹ï¼‰ãƒ‡ãƒ¢")
st.write(
    "CSV ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€**2ã¤ã®ç‰¹å¾´é‡**ã¨**ç›®çš„å¤‰æ•°**ã‚’é¸ã³ã€"
    "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã§å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»æ±ºå®šå¢ƒç•Œã®å¯è¦–åŒ–ï¼†æœªçŸ¥ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚"
)

# -----------------------------
# 1) ãƒ‡ãƒ¼ã‚¿å…¥åŠ›
# -----------------------------
st.header("1) ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

uploaded = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆUTF-8æƒ³å®šï¼‰", type=["csv"])

sample_hint_expander = st.expander("ãƒ¯ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã®åˆ—åï¼ˆå‚è€ƒï¼‰")
with sample_hint_expander:
    st.code(
        """['Class label', 'Alcohol', 'Malic acid', 'Ash',
 'Alcalinity of ash', 'Magnesium', 'Total phenols',
 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',
 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',
 'Proline']""",
        language="text",
    )
    st.write("â€» UCI Wine ã¨åŒã˜ä¸¦ã³ã®å ´åˆã€"
             "`Color intensity` ã¨ `Proline` ã‚’ä½¿ã†ã¨ã€å…ƒã‚³ãƒ¼ãƒ‰ã¨åŒã˜æ¡ä»¶ã§ã™ã€‚")

if uploaded is None:
    st.info("CSV ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# CSV èª­ã¿è¾¼ã¿
try:
    df = pd.read_csv(uploaded)
except Exception:
    uploaded.seek(0)
    df = pd.read_csv(uploaded, header=None)

st.subheader("å…ˆé ­5è¡Œ")
st.dataframe(df.head(), use_container_width=True)
st.write("ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶:", df.shape)

# -----------------------------
# 2) åˆ—ã®æŒ‡å®š
# -----------------------------
st.header("2) åˆ—ã®æŒ‡å®š")

numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
all_cols = df.columns.tolist()

default_label = "Class label" if "Class label" in df.columns else all_cols[0]
label_col = st.selectbox("ç›®çš„å¤‰æ•°ï¼ˆã‚¯ãƒ©ã‚¹ï¼‰åˆ—", options=all_cols, index=all_cols.index(default_label))

# åˆæœŸå€™è£œ
default_feat1 = "Color intensity" if "Color intensity" in df.columns else (numeric_cols[1] if len(numeric_cols) > 1 else all_cols[1])
default_feat2 = "Proline" if "Proline" in df.columns else (numeric_cols[2] if len(numeric_cols) > 2 else all_cols[2])

feat_cols = st.multiselect(
    "ç‰¹å¾´é‡ï¼ˆã¡ã‚‡ã†ã©2åˆ—ï¼‰", options=(numeric_cols if len(numeric_cols) >= 2 else all_cols),
    default=[c for c in [default_feat1, default_feat2] if c in all_cols]
)

if len(feat_cols) != 2:
    st.error("ç‰¹å¾´é‡ã¯ **2åˆ—** ã ã‘é¸ã‚“ã§ãã ã•ã„ã€‚")
    st.stop()

# å¯¾è±¡åˆ—ã ã‘ã«çµã£ã¦ã€æ•°å€¤å¤‰æ›ï¼†NaNå‡¦ç†ã‚’è¡Œã†å®‰å…¨ãªä½œæ¥­ç”¨DF
work_df = df[[label_col] + feat_cols].copy()

# ç‰¹å¾´é‡ã¯å¼·åˆ¶çš„ã«æ•°å€¤åŒ–ï¼ˆæ–‡å­—åˆ—ã‚„æ··åœ¨ã‚’å¸åï¼‰
for c in feat_cols:
    work_df[c] = pd.to_numeric(work_df[c], errors="coerce")

# ãƒ©ãƒ™ãƒ«ã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã®ã§ãã®ã¾ã¾ï¼ˆæ–‡å­—åˆ—ã§ã‚‚OKï¼‰
before_drop = len(work_df)
work_df = work_df.dropna(subset=feat_cols)  # ç‰¹å¾´é‡NaNè¡Œã¯é™¤å¤–
dropped = before_drop - len(work_df)
if dropped > 0:
    st.warning(f"ç‰¹å¾´é‡ã« NaN ãŒã‚ã£ãŸãŸã‚ **{dropped} è¡Œ** ã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚")

# -----------------------------
# 2.5) ç‰¹å¾´é‡ã®åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
# -----------------------------
st.header("3) ç‰¹å¾´é‡ã®åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰")
st.write("â€» ã‚µãƒ³ãƒ—ãƒ«å€¤å…¥åŠ›ã®å‰ã«ã€é¸æŠã—ãŸ2å¤‰æ•°ã®åˆ†å¸ƒã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

for col in feat_cols:
    vals = work_df[col].to_numpy()
    vals = vals[np.isfinite(vals)]
    fig = plt.figure(figsize=(6, 3.5))
    plt.hist(vals, bins=30)
    plt.xlabel(col)
    plt.ylabel("count")
    plt.title(f"Histogram: {col}")
    st.pyplot(fig, clear_figure=True)

# -----------------------------
# 3) å‰å‡¦ç†ã¨åˆ†å‰²
# -----------------------------
st.header("4) å‰å‡¦ç†ã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²")

col_a, col_b, col_c = st.columns(3)
with col_a:
    test_size = st.slider("ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º", 0.1, 0.5, 0.2, 0.05)
with col_b:
    random_state = st.number_input("random_state", min_value=0, max_value=9999, value=0, step=1)
with col_c:
    standardize = st.checkbox("æ¨™æº–åŒ–ï¼ˆStandardScalerï¼‰ã‚’ä½¿ã†", value=True)

X = work_df[feat_cols].to_numpy()
y_raw = work_df[label_col]

# ãƒ©ãƒ™ãƒ«ã‚’ 0..K-1 ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
le = LabelEncoder()
y = le.fit_transform(y_raw.astype(str))

# å­¦ç¿’/ãƒ†ã‚¹ãƒˆåˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=float(test_size), random_state=int(random_state), stratify=y
)

# æ¨™æº–åŒ–
if standardize:
    sc = StandardScaler()
    X_train_std = sc.fit_transform(X_train)
    X_test_std = sc.transform(X_test)
else:
    sc = None
    X_train_std = X_train.copy()
    X_test_std = X_test.copy()

st.write(
    f"**X_train**: {X_train_std.shape} / **y_train**: {y_train.shape}  |  "
    f"**X_test**: {X_test_std.shape} / **y_test**: {y_test.shape}"
)

# -----------------------------
# 4) ãƒ¢ãƒ‡ãƒ«è¨­å®šã¨å­¦ç¿’
# -----------------------------
st.header("5) ãƒ¢ãƒ‡ãƒ«è¨­å®šã¨å­¦ç¿’ï¼ˆLogisticRegressionï¼‰")

col1, col2, col3, col4 = st.columns(4)
with col1:
    C = st.select_slider("æ­£å‰‡åŒ–å¼·åº¦ C", options=[0.01, 0.1, 0.5, 1.0, 2.0, 10.0], value=1.0)
with col2:
    penalty = st.selectbox("ãƒšãƒŠãƒ«ãƒ†ã‚£", options=["l2"], index=0)
with col3:
    multi_class = st.selectbox("multi_class", options=["ovr", "multinomial"], index=0)
with col4:
    max_iter = st.number_input("max_iter", min_value=100, max_value=5000, value=200, step=50)

solver = "liblinear" if multi_class == "ovr" else "lbfgs"

model = LogisticRegression(
    max_iter=int(max_iter),
    multi_class=multi_class,
    solver=solver,
    C=float(C),
    penalty=penalty,
    random_state=int(random_state),
)

train_button = st.button("å­¦ç¿’ãƒ»è©•ä¾¡ã‚’å®Ÿè¡Œ", type="primary")

if train_button:
    # ===== å­¦ç¿’ =====
    model.fit(X_train_std, y_train)

    # ===== ç²¾åº¦ =====
    y_train_pred = model.predict(X_train_std)
    train_acc = accuracy_score(y_train, y_train_pred)

    y_test_pred = model.predict(X_test_std)
    test_acc = accuracy_score(y_test, y_test_pred)

    st.success(f"å­¦ç¿’å®Œäº† âœ…  |  è¨“ç·´: **{train_acc:.3f}**  /  ãƒ†ã‚¹ãƒˆ: **{test_acc:.3f}**")

    with st.expander("è©³ã—ã„ãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒ†ã‚¹ãƒˆï¼‰"):
        st.text("Classification report (test):")
        st.text(classification_report(y_test, y_test_pred, target_names=[str(c) for c in le.classes_]))
        st.write("æ··åŒè¡Œåˆ—ï¼ˆtestï¼‰")
        st.dataframe(pd.DataFrame(confusion_matrix(y_test, y_test_pred),
                                  index=[f"true_{c}" for c in le.classes_],
                                  columns=[f"pred_{c}" for c in le.classes_]))

    # ===== æ±ºå®šå¢ƒç•Œï¼ˆè¨“ç·´ï¼‰ =====
    st.subheader("æ±ºå®šå¢ƒç•Œï¼ˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼‰")
    fig1 = plt.figure(figsize=(7, 4))
    plot_decision_regions(X_train_std, y_train, clf=model)
    plt.xlabel(feat_cols[0] + (" (std)" if standardize else ""))
    plt.ylabel(feat_cols[1] + (" (std)" if standardize else ""))
    plt.title("Decision Regions - Train")
    st.pyplot(fig1, clear_figure=True)

    # ===== æ±ºå®šå¢ƒç•Œï¼ˆãƒ†ã‚¹ãƒˆï¼‰ =====
    st.subheader("æ±ºå®šå¢ƒç•Œï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰")
    fig2 = plt.figure(figsize=(7, 4))
    plot_decision_regions(X_test_std, y_test, clf=model)
    plt.xlabel(feat_cols[0] + (" (std)" if standardize else ""))
    plt.ylabel(feat_cols[1] + (" (std)" if standardize else ""))
    plt.title("Decision Regions - Test")
    st.pyplot(fig2, clear_figure=True)

    # ===== ä¿‚æ•°ã¨åˆ‡ç‰‡ =====
    st.subheader("ãƒ¢ãƒ‡ãƒ«ä¿‚æ•°ã¨åˆ‡ç‰‡")
    coef_df = pd.DataFrame(model.coef_, columns=[f"{feat_cols[0]}(coef)", f"{feat_cols[1]}(coef)"])
    coef_df.insert(0, "class_index", np.arange(coef_df.shape[0]))
    coef_df["original_label"] = [le.classes_[i] if i < len(le.classes_) else None for i in coef_df["class_index"]]
    st.dataframe(coef_df, use_container_width=True)

    intercept_df = pd.DataFrame({"intercept": model.intercept_})
    intercept_df["class_index"] = np.arange(intercept_df.shape[0])
    intercept_df["original_label"] = [le.classes_[i] if i < len(le.classes_) else None for i in intercept_df["class_index"]]
    st.dataframe(intercept_df, use_container_width=True)

    with st.expander("NumPyé…åˆ—ï¼ˆprint ç›¸å½“ï¼‰"):
        st.write("`model.coef_`")
        st.write(model.coef_)
        st.write("`model.intercept_`")
        st.write(model.intercept_)

    # -----------------------------
    # 6) æœªçŸ¥ãƒ‡ãƒ¼ã‚¿ 1ç‚¹ã®äºˆæ¸¬ï¼ˆå®‰å…¨ãª number_inputï¼‰
    # -----------------------------
    st.header("6) æœªçŸ¥ãƒ‡ãƒ¼ã‚¿ï¼ˆ1ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã®äºˆæ¸¬")

    def safe_stats(series: pd.Series):
        vals = pd.to_numeric(series, errors="coerce").to_numpy()
        vals = vals[np.isfinite(vals)]
        if vals.size == 0:
            return np.nan, np.nan, np.nan
        return np.nanmin(vals), np.nanmax(vals), np.nanmedian(vals)

    def number_input_safe(label: str, default: float, vmin: float, vmax: float):
        """
        min/max ãŒæœ‰é™ã‹ã¤ min<max ã®ã¨ãã ã‘å¢ƒç•Œã‚’ã‚»ãƒƒãƒˆã€‚
        ãã†ã§ãªã‘ã‚Œã°å¢ƒç•Œãªã— & step=1.0 ã«ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã€‚
        """
        kwargs = {"value": float(default) if np.isfinite(default) else 0.0, "format": "%.6f"}
        if np.isfinite(vmin) and np.isfinite(vmax) and (vmax > vmin):
            step = (vmax - vmin) / 100.0
            if step <= 0 or not np.isfinite(step):
                step = 1.0
            kwargs.update(
                min_value=float(vmin),
                max_value=float(vmax),
                step=float(step),
            )
        else:
            kwargs.update(step=1.0)
        return st.number_input(label, **kwargs)

    f1_min, f1_max, f1_med = safe_stats(work_df[feat_cols[0]])
    f2_min, f2_max, f2_med = safe_stats(work_df[feat_cols[1]])

    st.write("â€» å…¥åŠ›ã¯ **ç”Ÿã®å€¤**ï¼ˆæ¨™æº–åŒ–å‰ï¼‰ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚å¿…è¦ã«å¿œã˜ã¦å†…éƒ¨ã§åŒã˜ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’é©ç”¨ã—ã¾ã™ã€‚")

    u_f1 = number_input_safe(f"{feat_cols[0]} (sample)", f1_med, f1_min, f1_max)
    u_f2 = number_input_safe(f"{feat_cols[1]} (sample)", f2_med, f2_min, f2_max)

    predict_btn = st.button("æœªçŸ¥ã‚µãƒ³ãƒ—ãƒ«ã‚’äºˆæ¸¬", type="primary")

    if predict_btn:
        try:
            unknown_raw = np.array([[float(u_f1), float(u_f2)]], dtype=float)

            if standardize and sc is not None:
                unknown_std = sc.transform(unknown_raw)
            else:
                unknown_std = unknown_raw

            pred_idx = model.predict(unknown_std)
            # liblinear ã§ã‚‚ predict_proba ã¯åˆ©ç”¨å¯ï¼ˆovrï¼‰
            pred_prob = model.predict_proba(unknown_std)
            pred_label = le.inverse_transform(pred_idx)

            result_df = pd.DataFrame({
                "sample": ["sample_1"],
                feat_cols[0]: [unknown_raw[0, 0]],
                feat_cols[1]: [unknown_raw[0, 1]],
                "pred_class": [pred_label[0]],
                "pred_index": [int(pred_idx[0])]
            })

            st.subheader("äºˆæ¸¬çµæœï¼ˆã‚¯ãƒ©ã‚¹ï¼‰")
            st.dataframe(result_df, use_container_width=True)

            prob_cols = [f"proba_{c}" for c in le.classes_]
            prob_df = pd.DataFrame(pred_prob, columns=prob_cols, index=["sample_1"])
            st.subheader("äºˆæ¸¬ç¢ºç‡")
            st.dataframe(prob_df, use_container_width=True)
        except Exception as e:
            st.error("æœªçŸ¥ã‚µãƒ³ãƒ—ãƒ«ã®äºˆæ¸¬ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å…¥åŠ›å€¤ã¨åˆ—ã®å‹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            st.exception(e)

st.caption("â€» æ±ºå®šå¢ƒç•Œãƒ—ãƒ­ãƒƒãƒˆï¼ˆmlxtendï¼‰ã¯**2æ¬¡å…ƒç‰¹å¾´é‡ã®ã¿å¯¾å¿œ**ã§ã™ã€‚3åˆ—ä»¥ä¸Šã¯é¸ã°ãªã„ã§ãã ã•ã„ã€‚")

